---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 


#0-SETTING UP DATA; COMBINING TWO DATASETS 
```{r}
#0-SETTING UP DATA; COMBINING TWO DATASETS 
library(tidyverse)
library(dplyr)
library(fivethirtyeight)
data(drinks)
data(cousin_marriage)
cousin_marriage
dranks <- full_join(cousin_marriage, drinks, by="country")
dranks2 <- dranks %>% na.omit 
dranks2 %>% mutate(total_serving_of_alcohol = beer_servings+wine_servings+spirit_servings)
dranks3 <- dranks2 %>% mutate(total_serving_of_alcohol = beer_servings+wine_servings+spirit_servings)
dranks3 %>% summarize(median(total_serving_of_alcohol))
dranks4<-dranks3 %>%mutate(total_serving_of_alcohol = ntile(total_serving_of_alcohol,n = 2), total_serving_of_alcohol=recode(total_serving_of_alcohol, "low", "high"))
dranks4
dranks5<-dranks4 %>%mutate(percent = ntile(percent,n = 2), percent=recode(percent, "low", "high"))
dranks5
```
*I am working with a dataset renamed as 'dranks', which is originally two data sets, 'drinks' and 'cousin_marriage', that I have combined together. The drinks data set contains information on the total servings of different alcohols and the total liters of pure alcohol consumed by different countries. All of these are numeric variables and are presented as 'beer_servings' which measures the average number of beer servings per person in each country, 'wine_servings' which measures the average number of wine servings per person in each country, 'spirit_servings' which measures the average number of spirit servings per person in each country, 'total_liters_of_pure_alcohol' which measures the average total liters of pure alcohol per person in each country. I have also created the a new categorical variable, with two categories (high and low), named 'total_serving_of_alcohol' which measures the total servings of alcohol per person in each country.The cousin_marriage data set contains information on the percentage of people in the country that engage in some form of cousin marriage. The percentage of cousin marriages per country is given by the numeric variable 'percent', which I have also converted to a categorical variable with two categories (high and low). These data sets were acquired from the 'fivethirtyeight' package. Overall, there is a total number of 67 observations for each variable.*


#1-MANOVA, ANOVAs, POST-HOC T-TESTs
```{r}
#1-MANOVA, ANOVAs, POST-HOC T-TESTs
man1<-manova(cbind(beer_servings, spirit_servings, wine_servings)~percent,dranks4)
summary(man1)
summary.aov(man1)
pairwise.t.test(dranks5$beer_servings,dranks5$percent, p.adj="none")
pairwise.t.test(dranks5$spirit_servings,dranks5$percent, p.adj="none")
pairwise.t.test(dranks5$wine_servings,dranks5$percent, p.adj="none")
type1error<- 1-(0.95^7)
type1error 
bonferroni <- 0.05/7
bonferroni 
```

*A total of 7 tests were carried out. Specifically, one MANOVA, three ANOVAs, and 3 post-hoc T-tests. The probability of at least one type error (if unadjusted) is 0.3016627. The bonferroni correction adjusted the significance level to 0.007142857. Despite this change all seven tests had p-values below this significance level still and therefore it can still be concluded that significant difference does exist.*
#Briefly discuss some of the MANOVA assumptions and whether or not they are likely to have been met here



#2-RANDOMIZATION TEST: MEAN DIFFERENCE
```{r}
#2-RANDOMIZATION TEST: MEAN DIFFERENCE
dranks5 %>% na.omit
set.seed(348)
rand_mean<-vector()
for(i in 1:5000){
new<-data.frame(litres=sample(dranks5$total_litres_of_pure_alcohol),incest=dranks5$percent)
rand_mean[i]<-mean(new[new$incest=="high",]$litres)-mean(new[new$incest =="low",]$litres)}

mean(new[new$incest=="high",]$litres)-mean(new[new$incest=="low",]$litres)

hist(rand_mean,main="",ylab="", breaks =30); abline(v = c(-2.573262, 2.573262),col="red")
mean(abs(rand_mean)> 2.573262)
```
*The null hypothesis is that the mean total litres of alcohol consumed by people in a country is the same for a country with high percentage of cousin marriage vs. for a country with low percentage of cousin marriage, while the alternative hypothesis is that the mean total litres of alcohol consumed by people in a country is different for a country with high percentage of cousin marriage vs. for a country with low percentage of cousin marriage. The results of the randomization test show that the resulting p-value is 0.0044, which is below the significance level of 0.05. Therefore the null hypothesis can be rejected and it can be concluded that the alternative hypothesis is accepted. *


#3-LINEAR REGRESSION MODEL WITH INTERACTION
```{r}
#3 - HW#7-2.1
library(lmtest)
library(sandwich)
dranks4
dranks4$total_litres_of_pure_alcohol_c <- dranks4$total_litres_of_pure_alcohol - mean(dranks4$total_litres_of_pure_alcohol, na.rm = T)
fit<-lm(percent~total_litres_of_pure_alcohol_c*total_serving_of_alcohol,data=dranks4)
summary(fit)

coeftest(fit, vcov=vcovHC(fit))############################COEF issue when knitting 

dranks4 %>% select(percent, total_litres_of_pure_alcohol_c, total_serving_of_alcohol) %>% na.omit %>% ggplot(aes(total_litres_of_pure_alcohol_c, percent, color=total_serving_of_alcohol)) + 
geom_point()+geom_smooth(method="lm") + geom_vline(xintercept=mean(dranks4$total_litres_of_pure_alcohol_c,na.rm=T),lty=2)

resid<-fit$residuals
fitvals<-fit$fitted.values
ggplot()+geom_point(aes(fitvals,resid))+geom_hline(yintercept=0, color='red')

ggplot()+geom_histogram(aes(resid), bins=20)
ggplot()+geom_qq(aes(sample=resid))+geom_qq_line(aes(sample=resid))

```
*The intercept means that the Mean/predicted percent of cousin marriage for countries that consume high total servings of alcohol per person and with zero total_litres_of_pure_alcohol_c per person consumed is 5.57986.*

*total_litres_of_pure_alcohol_c means that for every 1-unit increase in total_litres_of_pure_alcohol_c, predicted percentage of cousin marriage goes down 0.90490 for this group.*

*total_serving_of_alcohollow  means that low total serving of alcohol countries with zero total_litres_of_pure_alcohol_c per person have predicted percentage of cousin marriage that is 31.95918 greater than countries with high total serving of alcohol per person with zero percentage of cousin marriage.*

*total_litres_of_pure_alcohol_c:total_serving_of_alcohollow means that the slope of percentage of cousin marriage on total_litres_of_pure_alcohol_c for countries with low total serving of alcohol per person is 3.18395 greater than for countries with high total serving of alcohol per person. *

What proportion of the variation in the outcome does your model explain? (4)
####ASK ABOUT THIS##########!!!!WHAT DOES THIS MEAN 

Check assumptions of linearity, normality, and homoskedasticity either graphically or using a hypothesis test (5)
*The assumptions for normality, linearity, and homoskedasticity are not met, as shown by the graphs.*
###are these correct? 

Regardless, recompute regression results with robust standard errors via coeftest(..., vcov=vcovHC(...)). Discuss significance of results, including any changes from before/after robust SEs if applicable.*The intercept and otal_litres_of_pure_alcohol_c are not signigicant as they have p-values above the significance level of 0.05. The total_serving_of_alcohollow and total_litres_of_pure_alcohol_c:total_serving_of_alcohollow are signicant because they have p-values below the significance level of 0.05. The standard errors remained practically ... what should I explain them  *
###what does it mean describe significant of resutls?



#4-BOOTSTRAPPING
```{r}
#4-BOOTSTRAPPING
samp_distn <- replicate(5000, {
  boot_dat<- dranks4[sample(nrow(dranks4), replace = TRUE),]
  Reg1<- lm(fit, data=boot_dat)
  coef(Reg1)
})
samp_distn %>% t %>% as.data.frame %>% summarize_all(sd)

```
*The SEs in this case were 2.692461, 0.5782093, 6.883675, 1.795046 for the intercept, total_litres_of_pure_alcohol_c, total_serving_of_alcohollow, and total_litres_of_pure_alcohol_c:total_serving_of_alcohollow, relatively. The original SEs were 2.8289, 0.6936, 4.4934, 1.2178 for the intercept, total_litres_of_pure_alcohol_c, total_serving_of_alcohollow, and total_litres_of_pure_alcohol_c:total_serving_of_alcohollow, relatively. The robust SEs were 3.02883, 0.64902, 5.23758, 1.28830 for the intercept, total_litres_of_pure_alcohol_c, total_serving_of_alcohollow, and total_litres_of_pure_alcohol_c:total_serving_of_alcohollow, relatively. From these results the standard errors changed from the original and robust SEs, but very little. *

#how do u describe p-values when I don't have any for bootstrapping. do I just explain how SE differ from robust ones above?!!!!!
Discuss any changes you observe in SEs and p-values using these SEs compared to the original SEs and the robust SEs)

```{r}
#5
library(ggplot2)
library(plotROC)
dranks6<-dranks5%>%mutate(y=ifelse(percent=="high",1,0))
dranks6
ogdranks<- glm(y~total_litres_of_pure_alcohol+wine_servings, data=dranks6, family= "binomial")
summary(ogdranks)
exp(coef(ogdranks))

dranks6$probs2<-predict(ogdranks, type = "response")
ggplot(dranks6)+geom_roc(aes(d=y, m=probs2))
calc_auc(ggplot(dranks6)+geom_roc(aes(d=y, m=probs2)))

probs2.1<-predict(ogdranks,type="response")
table(predict=as.numeric(probs2.1>.5),truth=dranks6$y)%>%addmargins

accuracy <- (26+29)/67
accuracy
sensitivity <-29/33
sensitivity 
specificity <-26/34
specificity
precisison <- 29/37
precisison 


dranks6$logit<-predict(ogdranks, type="link")
dranks6 %>% mutate(y=as.factor(y)) %>% ggplot()+geom_density(aes(logit, color=y, fill=y), alpha=.4)+geom_vline(xintercept = 0)+xlab("logit")

```

Interpret coefficient estimates in context (10)
*The coefficients are intercept, total_litres_of_pure_alcohol, and wine_servings. The intercept value of 10.8187916 means that the odds of high cousin marriage are 10.8187916 when the height is zero the predicted percentage of cousin marriage per country *
###FOR SURE ASK THIS!!!!!


Compute and discuss the Accuracy, Sensitivity (TPR), Specificity (TNR), Precision (PPV), and AUC of your model (5)
*The sensitivity is 0.8787879 , the specificity is 0.7647059, the precision is 0.7837838, the AUC is 0.9273619 , and the accuracy is 0.8208955. *

Generate an ROC curve (plot) and calculate AUC (either manually or with a package); interpret (5)
*The AUC is 0.9273619, which is a high value for AUC. AUC is the the area under the ROC curve. This high AUC value means that the model is very good at distinguishing between countries of high and low cousin marriage percentages. *



```{r}
#6
class_diag <- function(probs,truth){ 
  #CONFUSION MATRIX: CALCULATE ACCURACY, TPR, TNR, PPV 
  if(is.character(truth)==TRUE) truth<-as.factor(truth) 
  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1 
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),factor(truth, levels=c(0,1))) 
  acc=sum(diag(tab))/sum(tab) 
  sens=tab[2,2]/colSums(tab)[2] 
  spec=tab[1,1]/colSums(tab)[1] 
  ppv=tab[2,2]/rowSums(tab)[2] 
  
#CALCULATE EXACT AUC 
  ord<-order(probs, decreasing=TRUE) 
  probs <- probs[ord]; truth <- truth[ord] 
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth)) 
  dup <-c(probs[-1]>=probs[-length(probs)], FALSE) 
  TPR <-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1) 
  n <- length(TPR) 
  auc <- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n])) 
  data.frame(acc,sens,spec,ppv,auc) 
}
###########################################################Logistic regression and  in-sample classification diagnostics 
dranks6<-dranks5%>%mutate(y=ifelse(percent=="high",1,0))
dranks7<-dranks6%>%dplyr::select(-country,-percent)
fit <- glm(y~(.), data=dranks7, family ="binomial")
fit
probsX <- predict(fit, type ="response")
class_diag(probsX, dranks7$y)
table(predict=as.numeric(probsX>.5), truth=dranks7$y) %>% addmargins

accuracy <- (32+33)/67
accuracy
sensitivity <-33/33
sensitivity 
specificity <-32/34
specificity
precisison <- 33/35
precisison 

###########################################################10-fold CV
set.seed(1234)
k=10
F<-FALSE
data<- dranks7[sample(nrow(dranks7)),]
folds<- cut(seq(1:nrow(dranks7)), breaks=k, labels=F)
diags<-NULL
for(i in 1:k){
  train<-data[folds!=i,]
  test<-data[folds==i,]
  truth<-test$y
  fit<-glm(y~.,data=train, family ="binomial")
  probs<-predict(fit,newdata=test,type="response")
  diags<-rbind(diags,class_diag(probs,truth))
}
diags %>% summarize_all(mean)
summary(fit)
########################################################################LASSO
library(glmnet)
set.seed(1234)
x<- model.matrix(y~.+-1, data=dranks7)
y<- as.matrix(dranks7$y)
cv<-cv.glmnet(x,y,family="binomial")
lasso<-glmnet(x,y,family="binomial",lambda=cv$lambda.1se)
coef(lasso)
######################################################################### 10-fold CV on lasso variables
set.seed(1234)
k=10
F<-FALSE
data <- dranks7 %>% sample_frac 
folds <- ntile(1:nrow(data),n=10) 
diags<-NULL
for(i in 1:k){
train <- data[folds!=i,] 
test <- data[folds==i,] 
truth <- test$y 
fit<- glm(y~beer_servings+total_serving_of_alcohol,data=train, family="binomial") 
probs <- predict(fit, newdata=test, type="response")
diags<-rbind(diags,class_diag(probs,truth)) 
}
summarize_all(diags,mean)
```

Fit model, compute in-sample classification diagnostics (Accuracy, Sensitivity, Specificity, Precision, AUC), and interpret (5)
*For the in sample classification diagnostics, the sensitivity is 1, the specificity is 0.9411765, the precision is 0.9428571, the AUC is 0.9910873, and the accuracy is 0.9701493.*

Perform 10-fold (or repeated random sub-sampling) CV with the same model and report average out-of-sample classification diagnostics (Accuracy, Sensitivity, Specificity, Precision, and AUC); interpret AUC and compare with the in-sample metrics (10)

*For the out of sample classification diagnostics, the sensitivity is 0.89, the specificity is 0.9, the precision is 0.96, the AUC is  0.9333333, and the accuracy is 0.9. This AUC value of 0.9333333 is smaller than the in-sample AUC of 0.9910873, which means there is overfitting. *
###is it correct to say overfitting here!!!!!!

Perform LASSO on the same model/variables. Choose lambda to give the simplest model whose accuracy is near that of the best (i.e., lambda.1se). Discuss which variables are retained. (5)
*The variable that are retained are beer_servings and total_serving_of_alcohol.*

Perform 10-fold CV using only the variables lasso selected: compare model’s out-of-sample AUC to that of your logistic regressions above (5)
*The AUC gathered from the 10 fold CV on the lasso selected variables is 0.9583333. In comparison to the in-sample AUC of 0.9910873 and the 10 fold CV (with the same model used for the in-sample AUC) AUC of 0.9333333, this model has an AUC that lies between the two but less than the in-sample AUC.*
###is this sufficient


Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
